---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a principal researcher at [Tencent AI Lab](https://ai.tencent.com/ailab/index.html), working on machine learning and natural language processing. Before joining Tencent in March 2018, I worked at [Microsoft Research](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai/), Redmond, WA. I completed my PhD in Electrical Engineering at [University of California, Los Angeles](http://www.ucla.edu/) (UCLA), in June 2014, where I worked in Adaptive Systems Laboratory (ASL), supervised by Prof. [Ali H. Sayed](https://asl.epfl.ch/biography/).


Contact information
======
Email: chenjianshu at gmail dot com OR jianshuchen at global dot tencent dot com


Research interests
======
My research interests lie at the intersection of machine learning, natural language processing, and large language models. I focus on understanding and optimizing the synergy between knowledge and reasoning to develop next-generation large language model architectures and effective learning paradigms, with the objective of achieving strong compositional generalization and reasoning capabilities. I am passionate about tackling large-scale AI research projects, collaborating with interdisciplinary teams to address complex challenges, and driving robust and effective innovations in AI. Additionally, I maintain an active interest in reinforcement learning and optimization.

For more details, see my publications (also [google scholar](https://scholar.google.com/citations?user=jQeFWdoAAAAJ&hl=en))


Selected publications
======
1. Jiaao Chen, Xiaoman Pan, Kaiqiang Song, Dian Yu, Dong Yu, **Jianshu Chen**, “Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models”, arXiv preprint [arXiv:2308.00304], August 2023.
1. **Jianshu Chen**, “Learning Language Representations with Logical Inductive Bias”, Proc. International Conference on Learning Representations (ICLR), 2023.
1. X. Pan, W. Yao, H. Zhang, D. Yu, D. Yu, **Jianshu Chen**, “Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models”, Proc. International Conference on Learning Representations (ICLR), 2023 (**Spotlight**).
1. Y. Yang, W. Yao, H. Zhang, X. Wang, D. Yu, **Jianshu Chen**, “Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination”, Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022.
1. W. Chen, H. Wang, **Jianshu Chen**, Y. Zhang, H. Wang, S. Li, X. Zhou, W. Y. Wang, “TabFact: A Large-scale Dataset for Table-based Fact Verification”, Proc. International Conference on Learning Representations (ICLR), 2020
1. A. Liu, **Jianshu Chen**, M. Yu, Y. Zhai, X. Zhou, and J. Liu, “Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search”, Proc. International Conference on Learning Representations (ICLR), April 2020. (**Oral**)
1. B. Dai, A. Shaw, L. Li, L. Xiao, N. He, Z. Liu, **Jianshu Chen**, L. Song, “SBEED Learning: Convergent Control with Nonlinear Function Approximation”, Proc. International Conference on Machine Learning (ICML), 2018.
1. S. Du, **Jianshu Chen**, L. Li, L. Xiao, D. Zhou, ``Stochastic Variance Reduction Methods for Policy Evaluation'', Proc. International Conference on Machine Learning (ICML), 2017.
